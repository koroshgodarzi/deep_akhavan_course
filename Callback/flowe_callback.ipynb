{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "83bL1ItbPlc1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "flowers_root = tf.keras.utils.get_file( 'flower_photos',\n",
        "                                        'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                                        untar=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flowers_root"
      ],
      "metadata": {
        "id": "vzGnOMDJmu2I",
        "outputId": "f5c409cb-e008-48cf-cb2d-bdd6309b7e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/flower_photos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_set = tf.keras.utils.image_dataset_from_directory(os.path.join(flowers_root, 'flower_photos'),\n",
        "                                                        seed=1234,\n",
        "                                                        validation_split=0.3,\n",
        "                                                        subset='training')\n",
        "val_set = tf.keras.utils.image_dataset_from_directory(os.path.join(flowers_root, 'flower_photos'),\n",
        "                                                        seed=1234,\n",
        "                                                        validation_split=0.3,\n",
        "                                                        subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJTabC40Qbu2",
        "outputId": "c6cea755-e8bf-4a7d-aac9-b72d772ed682"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2569 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 1101 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set.cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_set = val_set.cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "XS6Jd-T0pBnQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, GlobalAveragePooling2D, BatchNormalization, Normalization\n",
        "\n",
        "model = Sequential([\n",
        "    Normalization(mean=0, variance=1, input_shape=(256, 256, 3)),\n",
        "    Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "f17KSNnmPr0o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YazgEnKdoK30"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', patience=5, min_delta=0.02, verbose=1)\n",
        "callback_earlystopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "\n",
        "model.fit(train_set, validation_data=val_set, epochs=100, callbacks=[callback_plateau, callback_earlystopping])"
      ],
      "metadata": {
        "id": "0Bk6QpLiqVa_",
        "outputId": "74e4ce4f-deef-42af-f1ec-8430f1334bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.4255 - loss: 1.3870 - val_accuracy: 0.4668 - val_loss: 1.3025 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5419 - loss: 1.1481 - val_accuracy: 0.4523 - val_loss: 1.2614 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5823 - loss: 1.0801 - val_accuracy: 0.5831 - val_loss: 1.0332 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6059 - loss: 1.0161 - val_accuracy: 0.5931 - val_loss: 1.0317 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6246 - loss: 0.9734 - val_accuracy: 0.6203 - val_loss: 0.9829 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6424 - loss: 0.9321 - val_accuracy: 0.6231 - val_loss: 1.0279 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6550 - loss: 0.9227 - val_accuracy: 0.6576 - val_loss: 0.9673 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6669 - loss: 0.8893 - val_accuracy: 0.6894 - val_loss: 0.8706 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6507 - loss: 0.8666 - val_accuracy: 0.5895 - val_loss: 1.1178 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.6790 - loss: 0.8409 - val_accuracy: 0.6712 - val_loss: 0.9425 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6732 - loss: 0.8307 - val_accuracy: 0.6067 - val_loss: 1.1929 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6838 - loss: 0.8171 - val_accuracy: 0.6521 - val_loss: 0.9875 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6851 - loss: 0.7987 - val_accuracy: 0.6094 - val_loss: 1.1560 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6984 - loss: 0.7758 - val_accuracy: 0.6785 - val_loss: 0.8915 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6987 - loss: 0.7770\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6988 - loss: 0.7774 - val_accuracy: 0.6730 - val_loss: 0.9158 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7142 - loss: 0.7598 - val_accuracy: 0.7584 - val_loss: 0.7085 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7248 - loss: 0.7098 - val_accuracy: 0.7584 - val_loss: 0.6868 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7319 - loss: 0.7036 - val_accuracy: 0.7511 - val_loss: 0.6954 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7301 - loss: 0.7006 - val_accuracy: 0.7548 - val_loss: 0.6952 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7255 - loss: 0.7021 - val_accuracy: 0.7548 - val_loss: 0.6912 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7425 - loss: 0.6875\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7424 - loss: 0.6880 - val_accuracy: 0.7629 - val_loss: 0.6821 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7430 - loss: 0.6766 - val_accuracy: 0.7629 - val_loss: 0.6792 - learning_rate: 1.0000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7513 - loss: 0.6716 - val_accuracy: 0.7593 - val_loss: 0.6791 - learning_rate: 1.0000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7479 - loss: 0.6846 - val_accuracy: 0.7566 - val_loss: 0.6787 - learning_rate: 1.0000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7480 - loss: 0.6717 - val_accuracy: 0.7557 - val_loss: 0.6783 - learning_rate: 1.0000e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7542 - loss: 0.6660 - val_accuracy: 0.7566 - val_loss: 0.6785 - learning_rate: 1.0000e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7463 - loss: 0.6758 - val_accuracy: 0.7548 - val_loss: 0.6772 - learning_rate: 1.0000e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7543 - loss: 0.6640\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7543 - loss: 0.6645 - val_accuracy: 0.7566 - val_loss: 0.6768 - learning_rate: 1.0000e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7515 - loss: 0.6648 - val_accuracy: 0.7548 - val_loss: 0.6769 - learning_rate: 1.0000e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7413 - loss: 0.6825 - val_accuracy: 0.7548 - val_loss: 0.6770 - learning_rate: 1.0000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7379 - loss: 0.6843 - val_accuracy: 0.7548 - val_loss: 0.6770 - learning_rate: 1.0000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7534 - loss: 0.6673 - val_accuracy: 0.7548 - val_loss: 0.6770 - learning_rate: 1.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7331 - loss: 0.6867\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7334 - loss: 0.6868 - val_accuracy: 0.7548 - val_loss: 0.6770 - learning_rate: 1.0000e-06\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d358d19fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRhAqSm-y31B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}