{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJoVg-1Klf1k",
        "outputId": "fdaea252-a3d7-40f2-c47a-94cd46819953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "\u001b[1m228813984/228813984\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "\n",
        "path = keras.utils.get_file('flower_photos',\n",
        "                            'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                            untar=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "trainset, valset = keras.utils.image_dataset_from_directory(os.path.join(path, 'flower_photos'),\n",
        "                                                            seed=420 ,\n",
        "                                                            validation_split=0.2,\n",
        "                                                            subset='both',\n",
        "                                                            image_size=(256, 256),\n",
        "                                                            batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDAOlVvVn-hD",
        "outputId": "e04dcb62-bd1b-406d-f670-54ca329c122a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras_hub\n",
        "\n",
        "preprocessor = keras.layers.Pipeline(\n",
        "    [\n",
        "        keras.layers.RandomBrightness(factor=0.1, value_range=(0, 255)),\n",
        "        keras.layers.RandomContrast(factor=(0.9, 1.1), value_range=(0, 255)),\n",
        "        keras.layers.RandomFlip(mode=\"horizontal\"),\n",
        "        keras.layers.RandomFlip(mode=\"vertical\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "classifier = keras_hub.models.ImageClassifier.from_preset(\n",
        "    \"densenet_121_imagenet\",\n",
        "    activation=\"softmax\",\n",
        "    num_classes=5,\n",
        "    preprocessor=preprocessor\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0KpkWHdoqsj",
        "outputId": "20a12886-ae86-4184-dba4-2ee46a0558d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/densenet/keras/densenet_121_imagenet/2/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 1.21MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "classifier.fit(\n",
        "    trainset,\n",
        "    validation_data=valset,\n",
        "    epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQPu-eceuMwp",
        "outputId": "516e9095-ba70-4aae-8f0e-9af186f94056"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 2s/step - accuracy: 0.6875 - loss: 0.8584 - val_accuracy: 0.9046 - val_loss: 0.2613\n",
            "Epoch 2/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 420ms/step - accuracy: 0.9267 - loss: 0.2014 - val_accuracy: 0.9183 - val_loss: 0.2208\n",
            "Epoch 3/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 416ms/step - accuracy: 0.9544 - loss: 0.1373 - val_accuracy: 0.9251 - val_loss: 0.2469\n",
            "Epoch 4/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 468ms/step - accuracy: 0.9700 - loss: 0.0947 - val_accuracy: 0.9401 - val_loss: 0.1732\n",
            "Epoch 5/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 484ms/step - accuracy: 0.9819 - loss: 0.0593 - val_accuracy: 0.9414 - val_loss: 0.1649\n",
            "Epoch 6/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 432ms/step - accuracy: 0.9900 - loss: 0.0458 - val_accuracy: 0.9441 - val_loss: 0.1712\n",
            "Epoch 7/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 426ms/step - accuracy: 0.9918 - loss: 0.0299 - val_accuracy: 0.9523 - val_loss: 0.1507\n",
            "Epoch 8/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 423ms/step - accuracy: 0.9917 - loss: 0.0322 - val_accuracy: 0.9332 - val_loss: 0.2041\n",
            "Epoch 9/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 424ms/step - accuracy: 0.9868 - loss: 0.0412 - val_accuracy: 0.9401 - val_loss: 0.2126\n",
            "Epoch 10/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 425ms/step - accuracy: 0.9931 - loss: 0.0309 - val_accuracy: 0.9564 - val_loss: 0.1578\n",
            "Epoch 11/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 475ms/step - accuracy: 0.9926 - loss: 0.0322 - val_accuracy: 0.9346 - val_loss: 0.2426\n",
            "Epoch 12/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 418ms/step - accuracy: 0.9909 - loss: 0.0314 - val_accuracy: 0.9414 - val_loss: 0.2324\n",
            "Epoch 13/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 420ms/step - accuracy: 0.9868 - loss: 0.0384 - val_accuracy: 0.9305 - val_loss: 0.2413\n",
            "Epoch 14/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 479ms/step - accuracy: 0.9876 - loss: 0.0318 - val_accuracy: 0.9469 - val_loss: 0.1947\n",
            "Epoch 15/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.9954 - loss: 0.0201 - val_accuracy: 0.9441 - val_loss: 0.1804\n",
            "Epoch 16/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 415ms/step - accuracy: 0.9945 - loss: 0.0214 - val_accuracy: 0.9387 - val_loss: 0.2249\n",
            "Epoch 17/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 474ms/step - accuracy: 0.9960 - loss: 0.0153 - val_accuracy: 0.9387 - val_loss: 0.2397\n",
            "Epoch 18/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 430ms/step - accuracy: 0.9931 - loss: 0.0280 - val_accuracy: 0.9292 - val_loss: 0.2750\n",
            "Epoch 19/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 473ms/step - accuracy: 0.9908 - loss: 0.0295 - val_accuracy: 0.9332 - val_loss: 0.2438\n",
            "Epoch 20/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 414ms/step - accuracy: 0.9966 - loss: 0.0179 - val_accuracy: 0.9482 - val_loss: 0.2036\n",
            "Epoch 21/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 426ms/step - accuracy: 0.9970 - loss: 0.0137 - val_accuracy: 0.9373 - val_loss: 0.2485\n",
            "Epoch 22/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 425ms/step - accuracy: 0.9946 - loss: 0.0208 - val_accuracy: 0.9510 - val_loss: 0.1785\n",
            "Epoch 23/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 423ms/step - accuracy: 0.9958 - loss: 0.0170 - val_accuracy: 0.9591 - val_loss: 0.1763\n",
            "Epoch 24/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 420ms/step - accuracy: 0.9973 - loss: 0.0131 - val_accuracy: 0.9496 - val_loss: 0.2126\n",
            "Epoch 25/25\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 423ms/step - accuracy: 0.9956 - loss: 0.0148 - val_accuracy: 0.9278 - val_loss: 0.2905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dee182b8b50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxX8QHL9ukd6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}