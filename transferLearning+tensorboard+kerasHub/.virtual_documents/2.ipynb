 ! pip install -q kaggle
 ! mkdir ~/.kaggle
 ! cp kaggle.json ~/.kaggle/
#  ! chmod 600 ~/.kaggle/kaggle.json
 ! kaggle competitions download -c /vuppalaadithyasairam/bone-fracture-detection-using-xrays


import kagglehub

# Download latest version
path = kagglehub.dataset_download("vuppalaadithyasairam/bone-fracture-detection-using-xrays")

print("Path to dataset files:", path)


import tensorflow as tf
import os
import glob

train_files = tf.data.Dataset.list_files(glob.glob(os.path.join(path, 'archive (6)', 'train', '*', '*'+'.jpg')),
                                        shuffle=True,
                                        seed=123)
val_files = tf.data.Dataset.list_files(glob.glob(os.path.join(path, 'archive (6)', 'val', '*', '*'+'.jpg')),
                                        shuffle=True,
                                        seed=123)


import matplotlib.pyplot as plt

for i in train_files.take(1):
  print(i)


def image_label_io(path):
  img = tf.io.read_file(path)
  img = tf.io.decode_jpeg(img, 1)
  img = tf.image.resize(img, (128, 128))
  img = tf.image.grayscale_to_rgb(img)
  img = tf.image.convert_image_dtype(img, tf.float32)

  l = tf.strings.split(path, os.path.sep)
  label = (l[-2]=='fractured')

  return (img, label)


def data_augment(img):
  img = tf.image.random_flip_left_right(img)
  img = tf.image.random_flip_up_down(img)
  img = tf.image.random_contrast(img, 0.9, 1.1)
  img = tf.image.random_brightness(img, 0.1)

  return img


def img_prep(img):
  img = tf.keras.applications.vgg16.preprocess_input(img)

  return img


train_set = train_files.map(image_label_io)
train_set = train_set.map(lambda x, y: (img_prep(x), y))
train_set = train_set.map(lambda x, y: (data_augment(x), y))
train_set = train_set.batch(32)
train_set.cache().prefetch(tf.data.AUTOTUNE)

val_set = val_files.map(image_label_io)
val_set = val_set.map(lambda x, y: (img_prep(x), y))
val_set = val_set.batch(32)
train_set.cache().prefetch(tf.data.AUTOTUNE)



from tensorflow.keras import Sequential
from tensorflow.keras.layers import  Dense, Dropout, Flatten

base_model =tf.keras.applications.VGG16(include_top=False,
                                        weights="imagenet",
                                        pooling='avg')
base_model.trainable = False

model = Sequential([
    base_model,
    Flatten(),
    Dropout(0.5),
    Dense(2, activation='softmax')
])


with open('lr.txt', 'r') as f:
  print(f.readlines()[1])


import numpy as np

def read_from_file(file_name):
  def lr_setter(epoch, lr):
    with open(file_name, 'r') as f:
      if epoch < 20:
        return np.float32(f.readlines()[0])
      if epoch >= 20:
        return np.float32(f.readlines()[1])
  return lr_setter


scheduler = read_from_file('lr.txt')
myCallback = tf.keras.callbacks.LearningRateScheduler(scheduler)


model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(train_set, epochs=25, validation_data=val_set, callbacks=[myCallback], initial_epoch=15)




